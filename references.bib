@article{10.1093/bioinformatics/btx801,
  author   = {Yang, Yang and Niehaus, Katherine E and Walker, Timothy M and Iqbal, Zamin and Walker, A Sarah and Wilson, Daniel J and Peto, Tim E A and Crook, Derrick W and Smith, E Grace and Zhu, Tingting and Clifton, David A},
  title    = {{Machine learning for classifying tuberculosis drug-resistance from DNA sequencing data}},
  journal  = {Bioinformatics},
  volume   = {34},
  number   = {10},
  pages    = {1666-1671},
  year     = {2017},
  month    = {12},
  abstract = {{Correct and rapid determination of Mycobacterium tuberculosis (MTB) resistance against available tuberculosis (TB) drugs is essential for the control and management of TB. Conventional molecular diagnostic test assumes that the presence of any well-studied single nucleotide polymorphisms is sufficient to cause resistance, which yields low sensitivity for resistance classification.Given the availability of DNA sequencing data from MTB, we developed machine learning models for a cohort of 1839 UK bacterial isolates to classify MTB resistance against eight anti-TB drugs (isoniazid, rifampicin, ethambutol, pyrazinamide, ciprofloxacin, moxifloxacin, ofloxacin, streptomycin) and to classify multi-drug resistance.Compared to previous rules-based approach, the sensitivities from the best-performing models increased by 2-4\\% for isoniazid, rifampicin and ethambutol to 97\\% (P \\&lt; 0.01), respectively; for ciprofloxacin and multi-drug resistant TB, they increased to 96\\%. For moxifloxacin and ofloxacin, sensitivities increased by 12 and 15\\% from 83 and 81\\% based on existing known resistance alleles to 95\\% and 96\\% (P \\&lt; 0.01), respectively. Particularly, our models improved sensitivities compared to the previous rules-based approach by 15 and 24\\% to 84 and 87\\% for pyrazinamide and streptomycin (P \\&lt; 0.01), respectively. The best-performing models increase the area-under-the-ROC curve by 10\\% for pyrazinamide and streptomycin (P \\&lt; 0.01), and 4–8\\% for other drugs (P \\&lt; 0.01).The details of source code are provided at http://www.robots.ox.ac.uk/~davidc/code.php.Supplementary data are available at Bioinformatics online.}},
  issn     = {1367-4803},
  doi      = {10.1093/bioinformatics/btx801},
  url      = {https://doi.org/10.1093/bioinformatics/btx801},
  eprint   = {https://academic.oup.com/bioinformatics/article-pdf/34/10/1666/25118199/btx801.pdf}
}

@article{10.1093/bioinformatics/btz067,
  author   = {Yang, Yang and Walker, Timothy M and Walker, A Sarah and Wilson, Daniel J and Peto, Timothy E A and Crook, Derrick W and Shamout, Farah and CRyPTIC Consortium  and Zhu, Tingting and Clifton, David A},
  title    = {{DeepAMR for predicting co-occurrent resistance of Mycobacterium tuberculosis}},
  journal  = {Bioinformatics},
  volume   = {35},
  number   = {18},
  pages    = {3240-3249},
  year     = {2019},
  month    = {01},
  abstract = {{Resistance co-occurrence within first-line anti-tuberculosis (TB) drugs is a common phenomenon. Existing methods based on genetic data analysis of Mycobacterium tuberculosis (MTB) have been able to predict resistance of MTB to individual drugs, but have not considered the resistance co-occurrence and cannot capture latent structure of genomic data that corresponds to lineages.We used a large cohort of TB patients from 16 countries across six continents where whole-genome sequences for each isolate and associated phenotype to anti-TB drugs were obtained using drug susceptibility testing recommended by the World Health Organization. We then proposed an end-to-end multi-task model with deep denoising auto-encoder (DeepAMR) for multiple drug classification and developed DeepAMR\_cluster, a clustering variant based on DeepAMR, for learning clusters in latent space of the data. The results showed that DeepAMR outperformed baseline model and four machine learning models with mean AUROC from 94.4\\% to 98.7\\% for predicting resistance to four first-line drugs [i.e. isoniazid (INH), ethambutol (EMB), rifampicin (RIF), pyrazinamide (PZA)], multi-drug resistant TB (MDR-TB) and pan-susceptible TB (PANS-TB: MTB that is susceptible to all four first-line anti-TB drugs). In the case of INH, EMB, PZA and MDR-TB, DeepAMR achieved its best mean sensitivity of 94.3\\%, 91.5\\%, 87.3\\% and 96.3\\%, respectively. While in the case of RIF and PANS-TB, it generated 94.2\\% and 92.2\\% sensitivity, which were lower than baseline model by 0.7\\% and 1.9\\%, respectively. t-SNE visualization shows that DeepAMR\_cluster captures lineage-related clusters in the latent space.The details of source code are provided at http://www.robots.ox.ac.uk/∼davidc/code.php.Supplementary data are available at Bioinformatics online.}},
  issn     = {1367-4803},
  doi      = {10.1093/bioinformatics/btz067},
  url      = {https://doi.org/10.1093/bioinformatics/btz067},
  eprint   = {https://academic.oup.com/bioinformatics/article-pdf/35/18/3240/30024571/btz067.pdf}
}

@book{10665-329368,
  author    = {World Health Organization},
  title     = {Global tuberculosis report 2019},
  year      = {2019},
  pages     = {xi, 283 p.},
  publisher = {World Health Organization},
  type      = {Publications}
}

@inproceedings{43442,
  title  = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author = {Sergey Ioffe and Christian Szegedy},
  year   = {2015},
  url    = {http://jmlr.org/proceedings/papers/v37/ioffe15.pdf},
  pages  = {448-456}
}

@article{article,
  author  = {Quan, T. and Bawa, Zharain and Foster, Dona and Walker, Tim and del Ojo, Carlos and Rathod, Priti and Iqbal, Zamin and Bradley, Phelim and Mowbray, Janet and Walker, A. and Crook, Derrick and Wyllie, David and Peto, Timothy and Smith, E.},
  year    = {2017},
  month   = {11},
  pages   = {JCM.01480-17},
  title   = {Evaluation of Whole-Genome Sequencing for Mycobacterial Species Identification and Drug Susceptibility Testing in a Clinical Setting: a Large-Scale Prospective Assessment of Performance against Line Probe Assays and Phenotyping},
  volume  = {56},
  journal = {Journal of Clinical Microbiology},
  doi     = {10.1128/JCM.01480-17}
}

@article{CHEN2019356,
  title    = {Beyond multidrug resistance: Leveraging rare variants with machine and statistical learning models in Mycobacterium tuberculosis resistance prediction},
  journal  = {EBioMedicine},
  volume   = {43},
  pages    = {356 - 369},
  year     = {2019},
  issn     = {2352-3964},
  doi      = {https://doi.org/10.1016/j.ebiom.2019.04.016},
  url      = {http://www.sciencedirect.com/science/article/pii/S2352396419302506},
  author   = {Michael L. Chen and Akshith Doddi and Jimmy Royer and Luca Freschi and Marco Schito and Matthew Ezewudo and Isaac S. Kohane and Andrew Beam and Maha Farhat},
  keywords = {, Multidrug-resistance, Extensively drug-resistant tuberculosis, Machine learning, Genome sequencing},
  abstract = {Background
The diagnosis of multidrug resistant and extensively drug resistant tuberculosis is a global health priority. Whole genome sequencing of clinical Mycobacterium tuberculosis isolates promises to circumvent the long wait times and limited scope of conventional phenotypic antimicrobial susceptibility, but gaps remain for predicting phenotype accurately from genotypic data especially for certain drugs. Our primary aim was to perform an exploration of statistical learning algorithms and genetic predictor sets using a rich dataset to build a high performing and fast predicting model to detect anti-tuberculosis drug resistance.
Methods
We collected targeted or whole genome sequencing and conventional drug resistance phenotyping data from 3601 Mycobacterium tuberculosis strains enriched for resistance to first- and second-line drugs, with 1228 multidrug resistant strains. We investigated the utility of (1) rare variants and variants known to be determinants of resistance for at least one drug and (2) machine and statistical learning architectures in predicting phenotypic drug resistance to 10 anti-tuberculosis drugs. Specifically, we investigated multitask and single task wide and deep neural networks, a multilayer perceptron, regularized logistic regression, and random forest classifiers.
Findings
The highest performing machine and statistical learning methods included both rare variants and those known to be causal of resistance for at least one drug. Both simpler L2 penalized regression and complex machine learning models had high predictive performance. The average AUCs for our highest performing model was 0.979 for first-line drugs and 0.936 for second-line drugs during repeated cross-validation. On an independent validation set, the highest performing model showed average AUCs, sensitivities, and specificities, respectively, of 0.937, 87.9%, and 92.7% for first-line drugs and 0.891, 82.0% and 90.1% for second-line drugs. Our method outperforms existing approaches based on direct association, with increased sum of sensitivity and specificity of 11.7% on first line drugs and 3.2% on second line drugs. Our method has higher predictive performance compared to previously reported machine learning models during cross-validation, with higher AUCs for 8 of 10 drugs.
Interpretation
Statistical models, especially those that are trained using both frequent and less frequent variants, significantly improve the accuracy of resistance prediction and hold promise in bringing sequencing technologies closer to the bedside.}
}

@article{DBLP:journals/corr/abs-1710-09412,
  author        = {Hongyi Zhang and
               Moustapha Ciss{\'{e}} and
               Yann N. Dauphin and
               David Lopez{-}Paz},
  title         = {mixup: Beyond Empirical Risk Minimization},
  journal       = {CoRR},
  volume        = {abs/1710.09412},
  year          = {2017},
  url           = {http://arxiv.org/abs/1710.09412},
  archiveprefix = {arXiv},
  eprint        = {1710.09412},
  timestamp     = {Mon, 13 Aug 2018 16:47:14 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1710-09412.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/TompsonGJLB14,
  author        = {Jonathan Tompson and
               Ross Goroshin and
               Arjun Jain and
               Yann LeCun and
               Christoph Bregler},
  title         = {Efficient Object Localization Using Convolutional Networks},
  journal       = {CoRR},
  volume        = {abs/1411.4280},
  year          = {2014},
  url           = {http://arxiv.org/abs/1411.4280},
  archiveprefix = {arXiv},
  eprint        = {1411.4280},
  timestamp     = {Mon, 13 Aug 2018 16:46:01 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/TompsonGJLB14.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@misc{hu2019squeezeandexcitation,
  title         = {Squeeze-and-Excitation Networks},
  author        = {Jie Hu and Li Shen and Samuel Albanie and Gang Sun and Enhua Wu},
  year          = {2019},
  eprint        = {1709.01507},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@article{JMLR:v15:srivastava14a,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929-1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@misc{kingma2017adam,
  title         = {Adam: A Method for Stochastic Optimization},
  author        = {Diederik P. Kingma and Jimmy Ba},
  year          = {2017},
  eprint        = {1412.6980},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{loshchilov2017sgdr,
  title         = {SGDR: Stochastic Gradient Descent with Warm Restarts},
  author        = {Ilya Loshchilov and Frank Hutter},
  year          = {2017},
  eprint        = {1608.03983},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{loshchilov2019decoupled,
  title         = {Decoupled Weight Decay Regularization},
  author        = {Ilya Loshchilov and Frank Hutter},
  year          = {2019},
  eprint        = {1711.05101},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{paszke2019pytorch,
  title         = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author        = {Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Köpf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
  year          = {2019},
  eprint        = {1912.01703},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{pereyra2017regularizing,
  title         = {Regularizing Neural Networks by Penalizing Confident Output Distributions},
  author        = {Gabriel Pereyra and George Tucker and Jan Chorowski and Łukasz Kaiser and Geoffrey Hinton},
  year          = {2017},
  eprint        = {1701.06548},
  archiveprefix = {arXiv},
  primaryclass  = {cs.NE}
}

@misc{qiao2020microbatch,
  title         = {Micro-Batch Training with Batch-Channel Normalization and Weight Standardization},
  author        = {Siyuan Qiao and Huiyu Wang and Chenxi Liu and Wei Shen and Alan Yuille},
  year          = {2020},
  eprint        = {1903.10520},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{shrivastava2016training,
  title         = {Training Region-based Object Detectors with Online Hard Example Mining},
  author        = {Abhinav Shrivastava and Abhinav Gupta and Ross Girshick},
  year          = {2016},
  eprint        = {1604.03540},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{vaswani2017attention,
  title         = {Attention Is All You Need},
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  year          = {2017},
  eprint        = {1706.03762},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{wu2018group,
  title         = {Group Normalization},
  author        = {Yuxin Wu and Kaiming He},
  year          = {2018},
  eprint        = {1803.08494},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}


